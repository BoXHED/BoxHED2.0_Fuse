{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ugrads/a/aa_ron_su/miniconda3/envs/clinical_t5/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/ugrads/a/aa_ron_su/physionet.org/files/clinical-t5/1.0.0/'\n",
    "data_path = '/data/datasets/mimiciv_notes/physionet.org/files/mimic-iv-note/2.2/note/discharge.csv'\n",
    "model_path = root + 'Clinical-T5-Base/'\n",
    "finetune_model_path = root + 'Clinical-T5-Base_ft_vent/'\n",
    "temivef_train_NOTE_TARGET1_FT_path = '/home/ugrads/a/aa_ron_su/JSS_SUBMISSION_NEW/data/till_end_mimic_iv_extra_features_train_NOTE_TARGET1_FT.csv'\n",
    "# temivef_test_NOTE_TARGET1_FT_path = '/home/ugrads/a/aa_ron_su/JSS_SUBMISSION_NEW/data/till_end_mimic_iv_extra_features_test_NOTE_TARGET1_FT.csv'\n",
    "model_out = root + \"meta_ft_classify.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading notes and target from /home/ugrads/a/aa_ron_su/JSS_SUBMISSION_NEW/data/till_end_mimic_iv_extra_features_train_NOTE_TARGET1_FT.csv\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(temivef_train_NOTE_TARGET1_FT_path)\n",
    "print(f\"reading notes and target from {temivef_train_NOTE_TARGET1_FT_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Clinical-T5-Base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Clinical-T5-Base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Clinical-T5-Base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fe3c89acb30>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mimic_iv_train_NOTE_EMBEDDINGS_target1 = pd.read_csv(mimic_iv_train_NOTE_EMBEDDINGS_target1_path) # this contains the embeddings and the target\n",
    "# df = mimic_iv_train_NOTE_EMBEDDINGS_target1.filter(regex='emb\\d{1,2}', axis=1)\n",
    "# df = pd.concat([df, mimic_iv_train_NOTE_EMBEDDINGS_target1['delta_in_2_days']], axis=1)\n",
    "\n",
    "# Use this later in pipeline.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(mimic_iv_train_NOTE_TARGET1_path)\n",
    "# df = df[['text','delta_in_2_days']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28724\n",
      "11753\n"
     ]
    }
   ],
   "source": [
    "# print(len(df))\n",
    "# df.dropna(inplace=True)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_function(example): \n",
    "#     return tokenizer(example, padding=\"max_length\", truncation=True, return_tensors = \"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mimic_iv_train_NOTE_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[0;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(mimic_iv_train_NOTE_path)\n\u001b[1;32m      3\u001b[0m df\u001b[39m.\u001b[39mdropna(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_pandas(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mimic_iv_train_NOTE_path' is not defined"
     ]
    }
   ],
   "source": [
    "# from datasets import Dataset\n",
    "# df = pd.read_csv(mimic_iv_train_NOTE_path)\n",
    "# df.dropna(inplace=True)\n",
    "# dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized note input_ids loaded from train_tensor.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os \n",
    "train_tensor_filename = \"train_tensor.pt\"\n",
    "\n",
    "train_tensor = None\n",
    "if os.path.isfile(train_tensor_filename):\n",
    "    train_tensor = torch.load(train_tensor_filename)\n",
    "    print(f\"tokenized note input_ids loaded from {train_tensor_filename}\")\n",
    "else:\n",
    "    train_texts = train['text'].tolist()\n",
    "    tokenized_train_notes = tokenizer(train_texts, truncation=True, padding=True, return_tensors = \"pt\")\n",
    "    train_tensor = tokenized_train_notes.input_ids\n",
    "    torch.save(train_tensor, train_tensor_filename)\n",
    "    print(f\"train notes tokenized and saved to {train_tensor_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5570,    10,     3,  ...,    10,  1714,     1],\n",
       "        [ 5570,    10,     3,  ...,  1678,    87,     1],\n",
       "        [ 5570,    10,     3,  ...,  2841,     5,     1],\n",
       "        ...,\n",
       "        [ 5570,    10,     3,  ...,    23,   106,     1],\n",
       "        [ 5570,    10,     3,  ...,    11, 16643,     1],\n",
       "        [ 5570,    10,     3,  ...,     7,    28,     1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def group_k_fold(ID, num_folds, seed=None):\n",
    "    ID             = ID.astype(int)\n",
    "    ID_unique_srtd = np.sort(np.unique(ID))\n",
    "\n",
    "    ID_counts = [len(ID_unique_srtd)//num_folds] * num_folds\n",
    "    for i in range(len(ID_unique_srtd)%num_folds):\n",
    "        ID_counts[i]+=1\n",
    "\n",
    "    assert sum(ID_counts)==len(ID_unique_srtd)\n",
    "\n",
    "    fold_idxs = np.hstack([[i]*id_count for i, id_count in enumerate(ID_counts)])\n",
    "\n",
    "    # if seed is not None:\n",
    "    #     with temp_seed(seed):\n",
    "    #         np.random.shuffle(fold_idxs)\n",
    "    # else:\n",
    "    np.random.shuffle(fold_idxs)\n",
    "\n",
    "    gkf = []\n",
    "    for fold_idx in range(num_folds):\n",
    "        train_ids = ID_unique_srtd[np.where(fold_idxs!=fold_idx)[0]]\n",
    "        test_ids  = ID_unique_srtd[np.where(fold_idxs==fold_idx)[0]]\n",
    "        gkf.append((np.where(np.isin(ID, train_ids))[0], np.where(np.isin(ID, test_ids))[0]))\n",
    "    \n",
    "    return gkf\n",
    "\n",
    "# define 5 fold cv\n",
    "num_folds = 5\n",
    "kfold = group_k_fold(train['ICUSTAY_ID'], num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(11669, 2904), (11668, 2905), (11635, 2938), (11660, 2913), (11660, 2913)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(len(kfold[i][0]), len(kfold[i][1])) for i in range(len(kfold))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(3)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "\n",
    "train_inputs = train_tensor\n",
    "train_labels = torch.tensor(train['delta_in_2_days'].to_numpy())\n",
    "train_dataset = TensorDataset(train_inputs.to(device), train_labels.to(device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9723,) (4850,)\n",
      "(9720,) (4853,)\n",
      "(9703,) (4870,)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold):\n",
    "    print(train_idx.shape, val_idx.shape)\n",
    "    val_set = Subset(train_dataset, val_idx)\n",
    "    val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "    train_set = Subset(train_dataset, train_idx)\n",
    "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    print(len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes_to_extract = df['text']\n",
    "# texts = notes_to_extract.tolist()\n",
    "# tokenized_notes_to_extract = tokenizer(texts, truncation=True, padding=True, return_tensors = \"pt\")\n",
    "\n",
    "# # test_note_to_extract = notes_to_extract.iloc[0]\n",
    "# # tokenized_test_note = tokenize_function(test_note_to_extract)\n",
    "# # tokenized_test_note.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from T5EncoderForSequenceClassification import T5EncoderForSequenceClassification, T5EncoderClassificationHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Config\n",
    "\n",
    "encoder = model.get_encoder() # we only need the clinical-t5 encoder for our purposes\n",
    "\n",
    "config = T5Config(\n",
    "    hidden_size=768,\n",
    "    classifier_dropout=None,\n",
    "    num_labels=2,\n",
    "    hidden_dropout_prob=0.01,\n",
    "    last_hidden_size=64\n",
    ")\n",
    "classifier = T5EncoderForSequenceClassification(encoder, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of T5EncoderForSequenceClassification(\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32115, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (classifier): T5EncoderClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (last_dense): Linear(in_features=768, out_features=64, bias=True)\n",
       "    (dropout): Dropout(p=0.01, inplace=False)\n",
       "    (out_proj): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.nn.utils import parameters_to_vector\n",
    "\n",
    "# num_params = len(parameters_to_vector(encoder.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109618560"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639938"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parameters_to_vector(classifier.classifier.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.encoder.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5EncoderClassificationHead(\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (last_dense): Linear(in_features=768, out_features=64, bias=True)\n",
       "  (dropout): Dropout(p=0.01, inplace=False)\n",
       "  (out_proj): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define your training data\n",
    "train_inputs = tokenized_notes_to_extract.input_ids\n",
    "# train_labels = torch.tensor(np.random.rand(len(train_inputs)))\n",
    "train_labels = torch.tensor(df['delta_in_2_days'].to_numpy())\n",
    "train_dataset = TensorDataset(train_inputs.to(device), train_labels.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# train_sampler = RandomSampler(train_dataset)\n",
    "# train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 1\n",
    "learning_rate = 5e-5\n",
    "adam_epsilon = 1e-8\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(classifier.classifier.parameters(), lr=learning_rate, eps=adam_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze encoder weights:\n",
    "for param in classifier.encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Step 0/735 | Loss 0.6700\n",
      "Epoch 1/1 | Step 10/735 | Loss 1.0951\n",
      "Epoch 1/1 | Step 20/735 | Loss 0.3144\n",
      "Epoch 1/1 | Step 30/735 | Loss 0.1830\n",
      "Epoch 1/1 | Step 40/735 | Loss 0.1017\n",
      "Epoch 1/1 | Step 50/735 | Loss 0.0713\n",
      "Epoch 1/1 | Step 60/735 | Loss 0.0397\n",
      "Epoch 1/1 | Step 70/735 | Loss 1.5947\n",
      "Epoch 1/1 | Step 80/735 | Loss 0.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [19:35<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m inputs, labels \u001b[39m=\u001b[39m batch\n\u001b[1;32m      7\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m outputs \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mforward(inputs, labels\u001b[39m=\u001b[39;49mlabels)\n\u001b[1;32m      9\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[1;32m     10\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/physionet.org/files/clinical-t5/1.0.0/T5EncoderForSequenceClassification.py:65\u001b[0m, in \u001b[0;36mT5EncoderForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_hidden_states, output_attentions, return_dict, return_embeddings)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ..., config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss),\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[39m    If `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m---> 65\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m     66\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m     67\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m     68\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m     69\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m     70\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m     71\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m     72\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     75\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m     76\u001b[0m logits, classifier_last_hidden_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/clinical_t5/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/clinical_t5/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:1040\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1028\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1029\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1040\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1041\u001b[0m         hidden_states,\n\u001b[1;32m   1042\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1043\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1044\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1045\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1046\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1047\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1048\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1049\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1050\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1051\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1052\u001b[0m     )\n\u001b[1;32m   1054\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/clinical_t5/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/clinical_t5/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:673\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    671\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[1;32m    674\u001b[0m     hidden_states,\n\u001b[1;32m    675\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    676\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    677\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    678\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    679\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    680\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    681\u001b[0m )\n\u001b[1;32m    682\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    683\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clinical_t5/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/clinical_t5/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:579\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    569\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    570\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    577\u001b[0m ):\n\u001b[1;32m    578\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 579\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelfAttention(\n\u001b[1;32m    580\u001b[0m         normed_hidden_states,\n\u001b[1;32m    581\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    582\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    583\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    584\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    585\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    586\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    587\u001b[0m     )\n\u001b[1;32m    588\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[1;32m    589\u001b[0m     outputs \u001b[39m=\u001b[39m (hidden_states,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/clinical_t5/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/clinical_t5/lib/python3.8/site-packages/transformers/models/t5/modeling_t5.py:550\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[39mif\u001b[39;00m layer_head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights \u001b[39m*\u001b[39m layer_head_mask\n\u001b[0;32m--> 550\u001b[0m attn_output \u001b[39m=\u001b[39m unshape(torch\u001b[39m.\u001b[39;49mmatmul(attn_weights, value_states))  \u001b[39m# (batch_size, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    551\u001b[0m attn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mo(attn_output)\n\u001b[1;32m    553\u001b[0m present_key_value_state \u001b[39m=\u001b[39m (key_states, value_states) \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder \u001b[39mand\u001b[39;00m use_cache) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "classifier.classifier.train()\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = classifier.forward(inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(classifier.classifier.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Print progress every 10 steps\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs} | Step {step}/{len(train_dataloader)} | Loss {loss.item():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRACT NOTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single_embedding = classifier.forward(train_inputs[0:2], labels = train_labels[0:2], return_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = classifier.forward(train_inputs, labels = train_labels, return_embeddings=True)\n",
    "# embeddings_df = pd.DataFrame({'embedding': list(embeddings.detach().numpy())})\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "# df = pd.concat([df, embeddings_df], axis = 1)\n",
    "# df.to_csv(mimic_iv_train_NOTE_EMBEDDINGS_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_df = pd.DataFrame({'embedding': list(embeddings.detach().numpy())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_small = df.iloc[0:5].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_small = pd.concat([df_small, embeddings_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merge embeddings with dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>t_start</th>\n",
       "      <th>t_end</th>\n",
       "      <th>NOTE_ID</th>\n",
       "      <th>text</th>\n",
       "      <th>delta</th>\n",
       "      <th>Capillary refill rate_1.0</th>\n",
       "      <th>Capillary refill rate_nan</th>\n",
       "      <th>Ethnicity_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>#past_IVs</th>\n",
       "      <th>t_from_last_IV_t_start</th>\n",
       "      <th>t_from_last_IV_t_end</th>\n",
       "      <th>INTIME</th>\n",
       "      <th>t_start_DT</th>\n",
       "      <th>time_since_note</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10248673</td>\n",
       "      <td>33680639</td>\n",
       "      <td>24.000</td>\n",
       "      <td>24.388</td>\n",
       "      <td>10248673-DS-5</td>\n",
       "      <td>\\nName:  ___                   Unit No:   ___...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.516622</td>\n",
       "      <td>168.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.250</td>\n",
       "      <td>11.167</td>\n",
       "      <td>2177-06-20 13:36:43</td>\n",
       "      <td>2177-06-21 13:36:43.000000000</td>\n",
       "      <td>901.611944</td>\n",
       "      <td>[0.08366300067315613, -0.09525524751737473, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10248673</td>\n",
       "      <td>33680639</td>\n",
       "      <td>24.388</td>\n",
       "      <td>25.038</td>\n",
       "      <td>10248673-DS-5</td>\n",
       "      <td>\\nName:  ___                   Unit No:   ___...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.516622</td>\n",
       "      <td>168.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.250</td>\n",
       "      <td>12.167</td>\n",
       "      <td>2177-06-20 13:36:43</td>\n",
       "      <td>2177-06-21 13:59:59.800000000</td>\n",
       "      <td>901.999944</td>\n",
       "      <td>[0.09037796095801452, -0.1034607368093436, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10248673</td>\n",
       "      <td>33680639</td>\n",
       "      <td>25.038</td>\n",
       "      <td>25.388</td>\n",
       "      <td>10248673-DS-5</td>\n",
       "      <td>\\nName:  ___                   Unit No:   ___...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.516622</td>\n",
       "      <td>168.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.900</td>\n",
       "      <td>12.817</td>\n",
       "      <td>2177-06-20 13:36:43</td>\n",
       "      <td>2177-06-21 14:38:59.800000000</td>\n",
       "      <td>902.649944</td>\n",
       "      <td>[0.10461136858709813, -0.08170781207205698, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10248673</td>\n",
       "      <td>33680639</td>\n",
       "      <td>25.388</td>\n",
       "      <td>25.421</td>\n",
       "      <td>10248673-DS-5</td>\n",
       "      <td>\\nName:  ___                   Unit No:   ___...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.516622</td>\n",
       "      <td>168.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.250</td>\n",
       "      <td>13.167</td>\n",
       "      <td>2177-06-20 13:36:43</td>\n",
       "      <td>2177-06-21 14:59:59.800000000</td>\n",
       "      <td>902.999944</td>\n",
       "      <td>[0.09262458924580079, -0.1298178264939714, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10248673</td>\n",
       "      <td>33680639</td>\n",
       "      <td>25.421</td>\n",
       "      <td>26.388</td>\n",
       "      <td>10248673-DS-5</td>\n",
       "      <td>\\nName:  ___                   Unit No:   ___...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.516622</td>\n",
       "      <td>168.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.283</td>\n",
       "      <td>13.200</td>\n",
       "      <td>2177-06-20 13:36:43</td>\n",
       "      <td>2177-06-21 15:01:58.600000000</td>\n",
       "      <td>903.032944</td>\n",
       "      <td>[0.09782734270128297, -0.11514283711793492, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  ICUSTAY_ID  t_start   t_end        NOTE_ID  \\\n",
       "0    10248673    33680639   24.000  24.388  10248673-DS-5   \n",
       "1    10248673    33680639   24.388  25.038  10248673-DS-5   \n",
       "2    10248673    33680639   25.038  25.388  10248673-DS-5   \n",
       "3    10248673    33680639   25.388  25.421  10248673-DS-5   \n",
       "4    10248673    33680639   25.421  26.388  10248673-DS-5   \n",
       "\n",
       "                                                text  delta  \\\n",
       "0   \\nName:  ___                   Unit No:   ___...      0   \n",
       "1   \\nName:  ___                   Unit No:   ___...      0   \n",
       "2   \\nName:  ___                   Unit No:   ___...      0   \n",
       "3   \\nName:  ___                   Unit No:   ___...      0   \n",
       "4   \\nName:  ___                   Unit No:   ___...      0   \n",
       "\n",
       "   Capillary refill rate_1.0  Capillary refill rate_nan  Ethnicity_1.0  ...  \\\n",
       "0                          0                          1              0  ...   \n",
       "1                          0                          1              0  ...   \n",
       "2                          0                          1              0  ...   \n",
       "3                          0                          1              0  ...   \n",
       "4                          0                          1              0  ...   \n",
       "\n",
       "         Age  Height  Weight  #past_IVs  t_from_last_IV_t_start  \\\n",
       "0  69.516622   168.0    66.0          1                  18.250   \n",
       "1  69.516622   168.0    66.0          1                  19.250   \n",
       "2  69.516622   168.0    66.0          1                  19.900   \n",
       "3  69.516622   168.0    66.0          1                  20.250   \n",
       "4  69.516622   168.0    66.0          1                  20.283   \n",
       "\n",
       "   t_from_last_IV_t_end               INTIME                     t_start_DT  \\\n",
       "0                11.167  2177-06-20 13:36:43  2177-06-21 13:36:43.000000000   \n",
       "1                12.167  2177-06-20 13:36:43  2177-06-21 13:59:59.800000000   \n",
       "2                12.817  2177-06-20 13:36:43  2177-06-21 14:38:59.800000000   \n",
       "3                13.167  2177-06-20 13:36:43  2177-06-21 14:59:59.800000000   \n",
       "4                13.200  2177-06-20 13:36:43  2177-06-21 15:01:58.600000000   \n",
       "\n",
       "   time_since_note                                          embedding  \n",
       "0       901.611944  [0.08366300067315613, -0.09525524751737473, 0....  \n",
       "1       901.999944  [0.09037796095801452, -0.1034607368093436, 0.2...  \n",
       "2       902.649944  [0.10461136858709813, -0.08170781207205698, 0....  \n",
       "3       902.999944  [0.09262458924580079, -0.1298178264939714, 0.2...  \n",
       "4       903.032944  [0.09782734270128297, -0.11514283711793492, 0....  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0552], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outputs['classifier_last_hidden_state'][0].shape\n",
    "# outputs['logits'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_with_dense = T5EncoderWithDense(encoder = encoder, num_classes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_layer_outputs = encoder_with_dense(inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0930]])]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder_with_dense.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0930]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dense_layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0374]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze the weights of the encoder layers\n",
    "# for param in model_encoder_only.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# # dataset = load_dataset('csv', data_files=mimic_iv_train_NOTE_path, split='train') # split = 'train\n",
    "# df = pd.read_csv(mimic_iv_train_NOTE_path)[['NOTE_ID', 'text']]\n",
    "# df.drop_duplicates(inplace=True)\n",
    "# df.dropna(inplace=True) \n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# inputs = tokenized_test_note\n",
    "# outputs = tokenized_test_note\n",
    "# outputs = model(input_ids = inputs.input_ids, attention_mask = inputs.attention_mask, decoder_input_ids = inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'encoder_last_hidden_state'])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import torch\n",
    "# inputs = tokenized_test_note\n",
    "# labels = torch.tensor([1]).unsqueeze(0)\n",
    "# outputs = model_encoder_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_note_to_encode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m encoder\u001b[39m.\u001b[39mforward(test_note_to_encode)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_note_to_encode' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m generated_outputs \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m notes_to_extract\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m      5\u001b[0m     input_text \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# generated_outputs = []\n",
    "# labels = torch.tensor([1]).unsqueeze(0)\n",
    "\n",
    "# for i, row in notes_to_extract.iterrows():\n",
    "#     input_text = row['text']\n",
    "#     input_ids = tokenizer.encode(input_text, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "#     outputs = model(**inputs, labels=labels)\n",
    "#     generated_outputs.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Generate a random target dataset with n = 1000\n",
    "# n = 1000\n",
    "# target_df = np.random.rand(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinical_t5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
