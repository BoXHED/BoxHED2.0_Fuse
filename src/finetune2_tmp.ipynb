{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import LongformerTokenizerFast, LongformerForSequenceClassification, Trainer, TrainingArguments, LongformerConfig, T5Config\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import wandb\n",
    "import argparse\n",
    "from functools import partial\n",
    "\n",
    "# FIXME import below need path from root\n",
    "from helpers import find_next_dir_index , explode_train_target, convert_to_list, merge_embs_to_seq, compute_metrics, group_train_val\n",
    "from MyTrainer import MyTrainer \n",
    "from BoXHED_Fuse.models.ClinicalLSTM import ClinicalLSTM\n",
    "# from ..models.ClinicalLSTM import ClinicalLSTM\n",
    "\n",
    "\n",
    "\n",
    "# ===== Initialize Args ===== \n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--test', action='store_true', help='enable testing mode')\n",
    "# parser.add_argument('--use-wandb', action = 'store_true', help = 'enable wandb', default=False)\n",
    "# parser.add_argument('--gpu-no', dest = 'GPU_NO', help='use GPU_NO specified (this may be a single number or several. eg: 1 or 1,2,3,4)')\n",
    "# parser.add_argument('--note-type', dest = 'note_type', help='which notes, radiology or discharge?')\n",
    "# parser.add_argument('--num-epochs', dest = 'num_epochs', help = 'num_epochs to train')\n",
    "# parser.add_argument('--noteid-mode', dest = 'noteid_mode', help = 'kw: all or recent')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args = argparse.Namespace\n",
    "args.test = True\n",
    "args.GPU_NO = -1\n",
    "args.note_type = 'radiology'\n",
    "args.num_epochs = 1\n",
    "args.noteid_mode = 'all'\n",
    "args.model_name = 'LSTM'\n",
    "\n",
    "args.num_epochs = int(args.num_epochs)\n",
    "\n",
    "model_name_ft1 = 'Clinical-T5-Base'\n",
    "train_embs_path = f'{os.getenv(\"BHF_ROOT\")}/JSS_SUBMISSION_NEW/data/embs{\"/testing\" if args.test else \"\"}/{model_name_ft1}_{args.note_type[:3]}_{args.noteid_mode}_out/from_epoch1/10/train_embs.pt'\n",
    "train_target_path = f'{os.getenv(\"BHF_ROOT\")}/JSS_SUBMISSION_NEW/data/targets{\"/testing\" if args.test else \"\"}/till_end_mimic_iv_extra_features_train_NOTE_TARGET_2_{args.note_type[:3]}_{args.noteid_mode}.csv'\n",
    "model_name = 'clinical_lstm'\n",
    "model_out_dir = f'{os.getenv(\"BHF_ROOT\")}/model_outputs/{model_name}_{args.note_type[:3]}_{args.noteid_mode}_out'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_train_embseq(train_embseq, train_target):\n",
    "    train_embseq = train_embseq.copy()\n",
    "    train_embseq['emb_seq_len'] = train_embseq['emb_seq'].apply(len)\n",
    "    train_target['NOTE_ID_SEQ_len'] = train_target['NOTE_ID_SEQ'].apply(len)\n",
    "    assert((train_target['NOTE_ID_SEQ_len'] == train_embseq['emb_seq_len']).all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created all dirs in model_out_dir /home/ugrads/a/aa_ron_su/BoXHED_Fuse/BoXHED_Fuse//model_outputs/clinical_lstm_rad_all_out/7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists(model_out_dir):\n",
    "    os.makedirs(model_out_dir)\n",
    "run_cntr = find_next_dir_index(model_out_dir)\n",
    "model_out_dir = os.path.join(model_out_dir, str(run_cntr))\n",
    "assert(not os.path.exists(model_out_dir))\n",
    "# os.makedirs(model_out_dir) # FIXME\n",
    "print(f'created all dirs in model_out_dir', model_out_dir)\n",
    "\n",
    "if args.test:\n",
    "    # train_target_path = os.path.join(os.path.dirname(train_target_path), 'testing', os.path.basename(train_target_path))\n",
    "    model_out_dir = os.path.join(os.path.dirname(model_out_dir), 'testing', os.path.basename(model_out_dir))\n",
    "\n",
    "\n",
    "# ===== Read Data =====\n",
    "train_embs = torch.load(train_embs_path)\n",
    "train_target = pd.read_csv(train_target_path, converters = {'NOTE_ID_SEQ': convert_to_list})\n",
    "target = 'delta_in_2_days' # FIXME\n",
    "train_target.rename(columns = {target:'label'}, inplace=True)\n",
    "# ===== Merge data into {note_embs_seq, label}, where note_seq is a list of embs =====\n",
    "train_target_exploded = explode_train_target(train_target)\n",
    "train_embs_df = pd.DataFrame()\n",
    "train_embs_df['emb'] = [np.array(e) for e in train_embs]\n",
    "train_embs_df = pd.concat([train_target_exploded, train_embs_df], axis=1)\n",
    "train_embseq = merge_embs_to_seq(train_target, train_embs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Validate =====\n",
    "\n",
    "validate_train_embseq(train_embseq, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Prepare train val split =====\n",
    "train_idxs, val_idxs = group_train_val(train_embseq['ICUSTAY_ID'])\n",
    "train_data = train_embseq.iloc[train_idxs]\n",
    "val_data = train_embseq.iloc[val_idxs]\n",
    "train_data = Dataset.from_pandas(train_data).select_columns(['emb_seq', 'label'])\n",
    "val_data = Dataset.from_pandas(val_data).select_columns(['emb_seq', 'label'])\n",
    "\n",
    "train_data.set_format('torch', columns=['emb_seq', 'label'])\n",
    "val_data.set_format('torch', columns=['emb_seq', 'label'])\n",
    "\n",
    "# ===== Train LSTM ===== \n",
    "\n",
    "clin_lstm = ClinicalLSTM()\n",
    "# main_finetune()\n",
    "\n",
    "\n",
    "\n",
    "# ===== Save Sequential Embeddings =====\n",
    "# extract_emb_seq()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "# maximum sequence length\n",
    "max_num_notes = 32\n",
    "doc_emb_size = 64 # 768\n",
    "    \n",
    "class Data_Encoder_FAST(data.Dataset):\n",
    "\n",
    "    def __init__(self, list_IDs, labels, df):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        # Load data and get label        \n",
    "        y = self.labels[index]\n",
    "        index = self.list_IDs[index]\n",
    "        doc_seqs = torch.cat(list(self.df[self.df.HADM_ID == index].DOC_EMB.values), 0)\n",
    "\n",
    "        xlnet_outputs = torch.zeros(size=(max_num_notes, doc_emb_size), dtype=torch.float)        \n",
    "        if len(doc_seqs) > max_num_notes:\n",
    "            xlnet_outputs[:max_num_notes] = doc_seqs[:max_num_notes]\n",
    "        else:\n",
    "            xlnet_outputs[:len(doc_seqs)] = doc_seqs\n",
    "\n",
    "        return xlnet_outputs.cuda(), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def main_finetune(lr, batch_size, train_epoch, dataFolder, prediction_label):\n",
    "    '''\n",
    "    finetune the model. Here, we are finetuning the LSTM!\n",
    "\n",
    "    \n",
    "    '''\n",
    "    lr = lr\n",
    "    BATCH_SIZE = batch_size\n",
    "    train_epoch = train_epoch\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    model = ClinicalLSTM()\n",
    "    model.cuda()\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model, dim = 0)\n",
    "            \n",
    "    print('--- Data Preparation ---')\n",
    "    \n",
    "    params = {'batch_size': BATCH_SIZE,\n",
    "              'shuffle': True,\n",
    "              'num_workers': 0, \n",
    "              'drop_last': True}\n",
    "\n",
    "    # df_train = pd.read_csv(dataFolder + '/train.csv')\n",
    "    # df_val = pd.read_csv(dataFolder + '/val.csv')\n",
    "    # df_test = pd.read_csv(dataFolder + '/test.csv')\n",
    "    \n",
    "    # doc_train = torch.load(dataFolder + '/train_doc_emb.pt')\n",
    "    # doc_val = torch.load(dataFolder + '/val_doc_emb.pt')\n",
    "    # doc_test = torch.load(dataFolder + '/test_doc_emb.pt')\n",
    "    \n",
    "    def doc_emb_to_df(doc, df):\n",
    "        output_seq = [torch.unsqueeze(doc[i],0) for i in range(doc.shape[0])]\n",
    "        df = df.assign(DOC_EMB = output_seq)\n",
    "        return df\n",
    "    \n",
    "    df_train = doc_emb_to_df(doc_train, df_train)\n",
    "    df_val = doc_emb_to_df(doc_val, df_val)\n",
    "    df_test = doc_emb_to_df(doc_test, df_test)\n",
    "    \n",
    "    if prediction_label == 'PMV':\n",
    "        train_unique = df_train[['HADM_ID','Label']].drop_duplicates().reset_index(drop = True)\n",
    "        val_unique = df_val[['HADM_ID','Label']].drop_duplicates().reset_index(drop = True)\n",
    "        test_unique = df_test[['HADM_ID','Label']].drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "        training_set = Data_Encoder_FAST(train_unique.HADM_ID.values, train_unique.Label.values, df_train)\n",
    "        training_generator = data.DataLoader(training_set, **params)\n",
    "        breakpoint() # dimensions of training_set? dataloader? \n",
    "\n",
    "        validation_set = Data_Encoder_FAST(val_unique.HADM_ID.values, val_unique.Label.values, df_val)\n",
    "        validation_generator = data.DataLoader(validation_set, **params)\n",
    "\n",
    "        testing_set = Data_Encoder_FAST(test_unique.HADM_ID.values, test_unique.Label.values, df_test)\n",
    "        testing_generator = data.DataLoader(testing_set, **params)\n",
    "    \n",
    "    elif prediction_label == 'Mortality':\n",
    "        train_unique = df_train[['HADM_ID','DEATH_90']].drop_duplicates().reset_index(drop = True)\n",
    "        val_unique = df_val[['HADM_ID','DEATH_90']].drop_duplicates().reset_index(drop = True)\n",
    "        test_unique = df_test[['HADM_ID','DEATH_90']].drop_duplicates().reset_index(drop = True)\n",
    "        \n",
    "        training_set = Data_Encoder_FAST(train_unique.HADM_ID.values, train_unique.DEATH_90.values, df_train)\n",
    "        training_generator = data.DataLoader(training_set, **params)\n",
    "\n",
    "        validation_set = Data_Encoder_FAST(val_unique.HADM_ID.values, val_unique.DEATH_90.values, df_val)\n",
    "        validation_generator = data.DataLoader(validation_set, **params)\n",
    "    \n",
    "        testing_set = Data_Encoder_FAST(test_unique.HADM_ID.values, test_unique.DEATH_90.values, df_test)\n",
    "        testing_generator = data.DataLoader(testing_set, **params)\n",
    "    else:\n",
    "        print(\"Please modify the label value for your own downstream prediction task.\")\n",
    "    \n",
    "    \n",
    "    opt = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    # early stopping\n",
    "    max_auc = 0\n",
    "    model_max = copy.deepcopy(model)\n",
    "   \n",
    "    print('--- Go for Training ---')\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    for epo in range(train_epoch):\n",
    "        model.train()\n",
    "        for i, (output, label) in enumerate(training_generator):\n",
    "            breakpoint() # what is the output? How does the LSTM take in data?\n",
    "            score = model(output.cuda())\n",
    "       \n",
    "            label = Variable(torch.from_numpy(np.array(label)).float()).cuda()\n",
    "            \n",
    "            loss_fct = torch.nn.BCELoss()\n",
    "            m = torch.nn.Sigmoid()\n",
    "            n = torch.squeeze(m(score))\n",
    "            \n",
    "            loss = loss_fct(n, label)\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "           \n",
    "        # every epoch test\n",
    "        with torch.set_grad_enabled(False):\n",
    "            auc, auprc, logits, loss = test_finetune(validation_generator, model)\n",
    "            if auc > max_auc:\n",
    "                model_max = copy.deepcopy(model)\n",
    "                max_auc = auc\n",
    "                 \n",
    "            print('Validation at Epoch '+ str(epo + 1) + ' , AUROC: '+ str(auc) + ' , AUPRC: ' + str(auprc))\n",
    "    \n",
    "    print('--- Go for Testing ---')\n",
    "    try:\n",
    "        with torch.set_grad_enabled(False):\n",
    "            auc, auprc, logits, loss = test_finetune(testing_generator, model_max)\n",
    "            print('Testing AUROC: ' + str(auc) + ' , AUPRC: ' + str(auprc) + ' , Test loss: '+str(loss))\n",
    "    except:\n",
    "        print('testing failed')\n",
    "    return model_max, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([45, 64])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['emb_seq'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embseq.ICUSTAY_ID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045718</td>\n",
       "      <td>0.029550</td>\n",
       "      <td>-0.006603</td>\n",
       "      <td>-0.030292</td>\n",
       "      <td>0.037942</td>\n",
       "      <td>-0.016469</td>\n",
       "      <td>-0.094294</td>\n",
       "      <td>-0.019970</td>\n",
       "      <td>-0.014836</td>\n",
       "      <td>0.082431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044541</td>\n",
       "      <td>0.055484</td>\n",
       "      <td>-0.101424</td>\n",
       "      <td>-0.070186</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.029890</td>\n",
       "      <td>0.090776</td>\n",
       "      <td>0.048945</td>\n",
       "      <td>0.032682</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014879</td>\n",
       "      <td>0.053706</td>\n",
       "      <td>-0.026616</td>\n",
       "      <td>-0.055694</td>\n",
       "      <td>0.026509</td>\n",
       "      <td>-0.097890</td>\n",
       "      <td>-0.020897</td>\n",
       "      <td>-0.097928</td>\n",
       "      <td>-0.014248</td>\n",
       "      <td>0.010718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011992</td>\n",
       "      <td>-0.055746</td>\n",
       "      <td>0.078403</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>-0.027869</td>\n",
       "      <td>-0.003987</td>\n",
       "      <td>0.028131</td>\n",
       "      <td>0.107723</td>\n",
       "      <td>0.034473</td>\n",
       "      <td>0.030731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.025563</td>\n",
       "      <td>0.094409</td>\n",
       "      <td>-0.040374</td>\n",
       "      <td>-0.070944</td>\n",
       "      <td>0.156529</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.025024</td>\n",
       "      <td>-0.080697</td>\n",
       "      <td>-0.032454</td>\n",
       "      <td>0.163034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018262</td>\n",
       "      <td>-0.037139</td>\n",
       "      <td>0.011970</td>\n",
       "      <td>-0.074624</td>\n",
       "      <td>0.048606</td>\n",
       "      <td>0.013519</td>\n",
       "      <td>0.093437</td>\n",
       "      <td>0.066523</td>\n",
       "      <td>-0.047791</td>\n",
       "      <td>-0.023772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034758</td>\n",
       "      <td>0.041230</td>\n",
       "      <td>0.053005</td>\n",
       "      <td>-0.012524</td>\n",
       "      <td>-0.050618</td>\n",
       "      <td>0.050894</td>\n",
       "      <td>-0.061397</td>\n",
       "      <td>-0.112498</td>\n",
       "      <td>0.039355</td>\n",
       "      <td>0.024527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.139965</td>\n",
       "      <td>0.122681</td>\n",
       "      <td>-0.043349</td>\n",
       "      <td>-0.016505</td>\n",
       "      <td>0.013531</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.054962</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>0.007898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.050177</td>\n",
       "      <td>0.039690</td>\n",
       "      <td>-0.013134</td>\n",
       "      <td>-0.057276</td>\n",
       "      <td>0.044675</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>-0.077664</td>\n",
       "      <td>-0.065639</td>\n",
       "      <td>-0.031200</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000984</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>0.053840</td>\n",
       "      <td>0.021765</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.047243</td>\n",
       "      <td>0.057308</td>\n",
       "      <td>0.103604</td>\n",
       "      <td>-0.004837</td>\n",
       "      <td>0.013525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.014579</td>\n",
       "      <td>0.068516</td>\n",
       "      <td>-0.006934</td>\n",
       "      <td>-0.046155</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>-0.097081</td>\n",
       "      <td>-0.084453</td>\n",
       "      <td>0.020215</td>\n",
       "      <td>0.074538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046301</td>\n",
       "      <td>0.034606</td>\n",
       "      <td>-0.050701</td>\n",
       "      <td>-0.110988</td>\n",
       "      <td>0.076473</td>\n",
       "      <td>0.027367</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>0.073614</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>-0.048693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.003845</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>-0.016001</td>\n",
       "      <td>-0.068146</td>\n",
       "      <td>-0.084224</td>\n",
       "      <td>-0.011092</td>\n",
       "      <td>-0.076685</td>\n",
       "      <td>-0.051530</td>\n",
       "      <td>-0.051489</td>\n",
       "      <td>0.038842</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026712</td>\n",
       "      <td>-0.009303</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>-0.022771</td>\n",
       "      <td>0.096020</td>\n",
       "      <td>0.043913</td>\n",
       "      <td>0.032230</td>\n",
       "      <td>0.028959</td>\n",
       "      <td>-0.101444</td>\n",
       "      <td>0.006620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.137261</td>\n",
       "      <td>0.076068</td>\n",
       "      <td>0.071644</td>\n",
       "      <td>0.054881</td>\n",
       "      <td>-0.108232</td>\n",
       "      <td>-0.139761</td>\n",
       "      <td>-0.130954</td>\n",
       "      <td>-0.088365</td>\n",
       "      <td>0.100763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214328</td>\n",
       "      <td>-0.034124</td>\n",
       "      <td>-0.086951</td>\n",
       "      <td>-0.035603</td>\n",
       "      <td>-0.018621</td>\n",
       "      <td>0.015729</td>\n",
       "      <td>-0.053997</td>\n",
       "      <td>0.040064</td>\n",
       "      <td>-0.000530</td>\n",
       "      <td>0.042536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.025607</td>\n",
       "      <td>0.021977</td>\n",
       "      <td>-0.025969</td>\n",
       "      <td>-0.026830</td>\n",
       "      <td>0.027689</td>\n",
       "      <td>0.028476</td>\n",
       "      <td>-0.121105</td>\n",
       "      <td>-0.104698</td>\n",
       "      <td>0.039678</td>\n",
       "      <td>0.127245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100903</td>\n",
       "      <td>0.085193</td>\n",
       "      <td>-0.091519</td>\n",
       "      <td>-0.071606</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>-0.020740</td>\n",
       "      <td>0.127078</td>\n",
       "      <td>0.006519</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.070626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.031743</td>\n",
       "      <td>0.113015</td>\n",
       "      <td>0.034682</td>\n",
       "      <td>-0.006114</td>\n",
       "      <td>-0.006546</td>\n",
       "      <td>-0.061236</td>\n",
       "      <td>-0.013636</td>\n",
       "      <td>-0.120102</td>\n",
       "      <td>-0.050542</td>\n",
       "      <td>0.134738</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140696</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>-0.068511</td>\n",
       "      <td>-0.057512</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>-0.024609</td>\n",
       "      <td>0.093552</td>\n",
       "      <td>0.073588</td>\n",
       "      <td>0.147881</td>\n",
       "      <td>-0.008034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.006413</td>\n",
       "      <td>0.073400</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>-0.035093</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.032547</td>\n",
       "      <td>-0.045356</td>\n",
       "      <td>-0.030846</td>\n",
       "      <td>0.019439</td>\n",
       "      <td>0.096794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035799</td>\n",
       "      <td>0.063068</td>\n",
       "      <td>-0.029667</td>\n",
       "      <td>-0.100024</td>\n",
       "      <td>0.028501</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>0.065867</td>\n",
       "      <td>-0.032114</td>\n",
       "      <td>-0.054099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.008868</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>-0.053068</td>\n",
       "      <td>-0.006125</td>\n",
       "      <td>0.018379</td>\n",
       "      <td>-0.046418</td>\n",
       "      <td>-0.018548</td>\n",
       "      <td>0.019612</td>\n",
       "      <td>0.071290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033081</td>\n",
       "      <td>0.062438</td>\n",
       "      <td>-0.016117</td>\n",
       "      <td>-0.102073</td>\n",
       "      <td>0.069959</td>\n",
       "      <td>0.044119</td>\n",
       "      <td>0.052977</td>\n",
       "      <td>0.064947</td>\n",
       "      <td>-0.030324</td>\n",
       "      <td>-0.036588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.046638</td>\n",
       "      <td>0.084531</td>\n",
       "      <td>0.082975</td>\n",
       "      <td>-0.036053</td>\n",
       "      <td>-0.003599</td>\n",
       "      <td>0.031197</td>\n",
       "      <td>-0.078514</td>\n",
       "      <td>-0.021192</td>\n",
       "      <td>0.052206</td>\n",
       "      <td>0.010567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009988</td>\n",
       "      <td>0.030690</td>\n",
       "      <td>-0.044073</td>\n",
       "      <td>-0.085046</td>\n",
       "      <td>0.106871</td>\n",
       "      <td>-0.035433</td>\n",
       "      <td>0.060999</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.062490</td>\n",
       "      <td>-0.033624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.016510</td>\n",
       "      <td>0.042524</td>\n",
       "      <td>-0.018867</td>\n",
       "      <td>-0.077157</td>\n",
       "      <td>-0.050874</td>\n",
       "      <td>0.050737</td>\n",
       "      <td>-0.015112</td>\n",
       "      <td>-0.024029</td>\n",
       "      <td>-0.042159</td>\n",
       "      <td>0.020356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001702</td>\n",
       "      <td>-0.014505</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>-0.034258</td>\n",
       "      <td>0.044570</td>\n",
       "      <td>0.023196</td>\n",
       "      <td>0.056535</td>\n",
       "      <td>-0.006508</td>\n",
       "      <td>-0.065058</td>\n",
       "      <td>0.010104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.019388</td>\n",
       "      <td>0.029920</td>\n",
       "      <td>-0.008551</td>\n",
       "      <td>-0.065558</td>\n",
       "      <td>0.058580</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>-0.003221</td>\n",
       "      <td>-0.070910</td>\n",
       "      <td>-0.041263</td>\n",
       "      <td>-0.026573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041038</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.049116</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.021475</td>\n",
       "      <td>0.036974</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>0.082808</td>\n",
       "      <td>0.014177</td>\n",
       "      <td>0.013240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.048493</td>\n",
       "      <td>0.006817</td>\n",
       "      <td>-0.049377</td>\n",
       "      <td>0.056934</td>\n",
       "      <td>0.036149</td>\n",
       "      <td>-0.097038</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>-0.034286</td>\n",
       "      <td>0.047402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004971</td>\n",
       "      <td>0.076468</td>\n",
       "      <td>-0.096170</td>\n",
       "      <td>-0.012768</td>\n",
       "      <td>0.007764</td>\n",
       "      <td>-0.002510</td>\n",
       "      <td>0.078921</td>\n",
       "      <td>0.041989</td>\n",
       "      <td>0.011758</td>\n",
       "      <td>-0.039439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.119825</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.094573</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>-0.052345</td>\n",
       "      <td>0.036623</td>\n",
       "      <td>-0.082182</td>\n",
       "      <td>-0.006148</td>\n",
       "      <td>0.100742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059317</td>\n",
       "      <td>-0.099608</td>\n",
       "      <td>0.027492</td>\n",
       "      <td>-0.099546</td>\n",
       "      <td>-0.006016</td>\n",
       "      <td>-0.100893</td>\n",
       "      <td>0.014221</td>\n",
       "      <td>0.011576</td>\n",
       "      <td>0.080198</td>\n",
       "      <td>-0.050756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.054157</td>\n",
       "      <td>0.008091</td>\n",
       "      <td>-0.010715</td>\n",
       "      <td>0.015597</td>\n",
       "      <td>-0.019786</td>\n",
       "      <td>-0.066090</td>\n",
       "      <td>-0.101331</td>\n",
       "      <td>0.051375</td>\n",
       "      <td>0.088146</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100255</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>-0.006339</td>\n",
       "      <td>-0.099822</td>\n",
       "      <td>0.058728</td>\n",
       "      <td>0.027287</td>\n",
       "      <td>0.053411</td>\n",
       "      <td>0.059347</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>0.008276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.033059</td>\n",
       "      <td>0.043817</td>\n",
       "      <td>-0.002383</td>\n",
       "      <td>-0.035188</td>\n",
       "      <td>0.023646</td>\n",
       "      <td>-0.009360</td>\n",
       "      <td>-0.000830</td>\n",
       "      <td>-0.057167</td>\n",
       "      <td>-0.057007</td>\n",
       "      <td>0.029630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007441</td>\n",
       "      <td>-0.005505</td>\n",
       "      <td>0.039446</td>\n",
       "      <td>0.029894</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>0.033013</td>\n",
       "      <td>0.019739</td>\n",
       "      <td>0.114780</td>\n",
       "      <td>0.070594</td>\n",
       "      <td>0.058180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.011671</td>\n",
       "      <td>0.085089</td>\n",
       "      <td>0.023694</td>\n",
       "      <td>-0.032689</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.021086</td>\n",
       "      <td>-0.048543</td>\n",
       "      <td>-0.016978</td>\n",
       "      <td>0.043538</td>\n",
       "      <td>0.113206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033911</td>\n",
       "      <td>0.037789</td>\n",
       "      <td>-0.041902</td>\n",
       "      <td>-0.152079</td>\n",
       "      <td>0.064484</td>\n",
       "      <td>0.004390</td>\n",
       "      <td>0.034925</td>\n",
       "      <td>0.067526</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>-0.056446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.016503</td>\n",
       "      <td>0.021980</td>\n",
       "      <td>-0.047566</td>\n",
       "      <td>-0.010999</td>\n",
       "      <td>0.046883</td>\n",
       "      <td>-0.020190</td>\n",
       "      <td>-0.088583</td>\n",
       "      <td>-0.108168</td>\n",
       "      <td>0.036541</td>\n",
       "      <td>0.079289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068870</td>\n",
       "      <td>0.068981</td>\n",
       "      <td>-0.088746</td>\n",
       "      <td>-0.072308</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>-0.009332</td>\n",
       "      <td>0.113710</td>\n",
       "      <td>0.034265</td>\n",
       "      <td>0.016250</td>\n",
       "      <td>0.044791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.025232</td>\n",
       "      <td>0.076471</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>-0.036584</td>\n",
       "      <td>-0.016119</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>-0.045926</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.096071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030195</td>\n",
       "      <td>0.032805</td>\n",
       "      <td>-0.033361</td>\n",
       "      <td>-0.145777</td>\n",
       "      <td>0.094102</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.028587</td>\n",
       "      <td>0.084461</td>\n",
       "      <td>-0.006333</td>\n",
       "      <td>-0.068345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.014369</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>-0.034077</td>\n",
       "      <td>-0.004060</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>-0.006948</td>\n",
       "      <td>-0.075494</td>\n",
       "      <td>-0.071101</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.079337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027003</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>-0.100435</td>\n",
       "      <td>-0.103675</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.014840</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.032527</td>\n",
       "      <td>0.010783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.031779</td>\n",
       "      <td>0.120885</td>\n",
       "      <td>-0.003923</td>\n",
       "      <td>0.062244</td>\n",
       "      <td>0.017966</td>\n",
       "      <td>-0.019144</td>\n",
       "      <td>0.025218</td>\n",
       "      <td>-0.099728</td>\n",
       "      <td>0.018702</td>\n",
       "      <td>0.172826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044301</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>0.022779</td>\n",
       "      <td>-0.113362</td>\n",
       "      <td>0.010419</td>\n",
       "      <td>-0.049550</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.018996</td>\n",
       "      <td>0.047716</td>\n",
       "      <td>0.043224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.009189</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>-0.016392</td>\n",
       "      <td>-0.031908</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>-0.027613</td>\n",
       "      <td>-0.080755</td>\n",
       "      <td>-0.123708</td>\n",
       "      <td>-0.000170</td>\n",
       "      <td>0.054489</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092378</td>\n",
       "      <td>0.027401</td>\n",
       "      <td>-0.077702</td>\n",
       "      <td>-0.088449</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>-0.003518</td>\n",
       "      <td>0.073781</td>\n",
       "      <td>0.033179</td>\n",
       "      <td>0.053518</td>\n",
       "      <td>0.011284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.022119</td>\n",
       "      <td>0.090834</td>\n",
       "      <td>0.046463</td>\n",
       "      <td>0.047062</td>\n",
       "      <td>0.014813</td>\n",
       "      <td>-0.061685</td>\n",
       "      <td>-0.001193</td>\n",
       "      <td>-0.141387</td>\n",
       "      <td>-0.021373</td>\n",
       "      <td>0.126997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023251</td>\n",
       "      <td>-0.048002</td>\n",
       "      <td>-0.019405</td>\n",
       "      <td>-0.080486</td>\n",
       "      <td>-0.006526</td>\n",
       "      <td>-0.043165</td>\n",
       "      <td>-0.007972</td>\n",
       "      <td>0.030078</td>\n",
       "      <td>0.064146</td>\n",
       "      <td>-0.027547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.015711</td>\n",
       "      <td>0.032453</td>\n",
       "      <td>-0.022631</td>\n",
       "      <td>-0.042749</td>\n",
       "      <td>0.036292</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>-0.093948</td>\n",
       "      <td>-0.103322</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.073889</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078985</td>\n",
       "      <td>0.045724</td>\n",
       "      <td>-0.081404</td>\n",
       "      <td>-0.079405</td>\n",
       "      <td>-0.019545</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.097253</td>\n",
       "      <td>0.031109</td>\n",
       "      <td>0.037987</td>\n",
       "      <td>0.029841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.028160</td>\n",
       "      <td>0.076047</td>\n",
       "      <td>0.070391</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>-0.015330</td>\n",
       "      <td>-0.012267</td>\n",
       "      <td>-0.057451</td>\n",
       "      <td>-0.121926</td>\n",
       "      <td>0.064830</td>\n",
       "      <td>0.040397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095598</td>\n",
       "      <td>0.071496</td>\n",
       "      <td>-0.043650</td>\n",
       "      <td>-0.002025</td>\n",
       "      <td>0.059618</td>\n",
       "      <td>0.051520</td>\n",
       "      <td>0.037757</td>\n",
       "      <td>0.027529</td>\n",
       "      <td>-0.037450</td>\n",
       "      <td>0.041332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.031323</td>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.067633</td>\n",
       "      <td>-0.026719</td>\n",
       "      <td>0.024059</td>\n",
       "      <td>-0.021315</td>\n",
       "      <td>-0.114488</td>\n",
       "      <td>-0.051262</td>\n",
       "      <td>0.054604</td>\n",
       "      <td>0.044275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085564</td>\n",
       "      <td>0.028727</td>\n",
       "      <td>-0.090319</td>\n",
       "      <td>-0.092322</td>\n",
       "      <td>0.037236</td>\n",
       "      <td>-0.036258</td>\n",
       "      <td>0.070299</td>\n",
       "      <td>0.025292</td>\n",
       "      <td>0.071249</td>\n",
       "      <td>-0.021214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.014051</td>\n",
       "      <td>0.081975</td>\n",
       "      <td>0.038148</td>\n",
       "      <td>-0.054412</td>\n",
       "      <td>-0.000611</td>\n",
       "      <td>0.027921</td>\n",
       "      <td>-0.041973</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>-0.012894</td>\n",
       "      <td>0.108911</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042799</td>\n",
       "      <td>0.045160</td>\n",
       "      <td>-0.031504</td>\n",
       "      <td>-0.162719</td>\n",
       "      <td>0.081387</td>\n",
       "      <td>0.022862</td>\n",
       "      <td>0.033945</td>\n",
       "      <td>0.048436</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>-0.061317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.007677</td>\n",
       "      <td>0.031448</td>\n",
       "      <td>-0.026275</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036247</td>\n",
       "      <td>0.056189</td>\n",
       "      <td>-0.099280</td>\n",
       "      <td>0.032602</td>\n",
       "      <td>-0.042544</td>\n",
       "      <td>0.053963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.100519</td>\n",
       "      <td>-0.091380</td>\n",
       "      <td>-0.021080</td>\n",
       "      <td>0.012255</td>\n",
       "      <td>0.055066</td>\n",
       "      <td>0.029710</td>\n",
       "      <td>0.055870</td>\n",
       "      <td>-0.022828</td>\n",
       "      <td>-0.055748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.008793</td>\n",
       "      <td>0.035975</td>\n",
       "      <td>-0.047498</td>\n",
       "      <td>-0.052630</td>\n",
       "      <td>0.060049</td>\n",
       "      <td>0.049904</td>\n",
       "      <td>-0.100061</td>\n",
       "      <td>0.027434</td>\n",
       "      <td>-0.005198</td>\n",
       "      <td>0.060145</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023003</td>\n",
       "      <td>0.066782</td>\n",
       "      <td>-0.107320</td>\n",
       "      <td>-0.062841</td>\n",
       "      <td>-0.020343</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>0.075387</td>\n",
       "      <td>0.066222</td>\n",
       "      <td>-0.025534</td>\n",
       "      <td>-0.024558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.013261</td>\n",
       "      <td>-0.054100</td>\n",
       "      <td>-0.033012</td>\n",
       "      <td>0.050905</td>\n",
       "      <td>-0.060793</td>\n",
       "      <td>-0.114428</td>\n",
       "      <td>-0.142502</td>\n",
       "      <td>-0.007025</td>\n",
       "      <td>0.055599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077932</td>\n",
       "      <td>0.049478</td>\n",
       "      <td>-0.107377</td>\n",
       "      <td>-0.069877</td>\n",
       "      <td>-0.022323</td>\n",
       "      <td>-0.023003</td>\n",
       "      <td>0.103833</td>\n",
       "      <td>0.040407</td>\n",
       "      <td>0.033367</td>\n",
       "      <td>0.039933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.004711</td>\n",
       "      <td>0.037684</td>\n",
       "      <td>-0.028149</td>\n",
       "      <td>-0.042811</td>\n",
       "      <td>0.046165</td>\n",
       "      <td>0.054393</td>\n",
       "      <td>-0.088368</td>\n",
       "      <td>0.031845</td>\n",
       "      <td>-0.043457</td>\n",
       "      <td>0.063833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.080604</td>\n",
       "      <td>-0.088755</td>\n",
       "      <td>-0.039875</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.052876</td>\n",
       "      <td>0.029805</td>\n",
       "      <td>0.068806</td>\n",
       "      <td>-0.020217</td>\n",
       "      <td>-0.053999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.025028</td>\n",
       "      <td>0.023958</td>\n",
       "      <td>-0.001213</td>\n",
       "      <td>-0.057603</td>\n",
       "      <td>-0.073663</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>-0.040789</td>\n",
       "      <td>-0.035487</td>\n",
       "      <td>-0.040247</td>\n",
       "      <td>0.020686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019669</td>\n",
       "      <td>-0.019787</td>\n",
       "      <td>0.024693</td>\n",
       "      <td>-0.043907</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.034142</td>\n",
       "      <td>0.049083</td>\n",
       "      <td>0.015043</td>\n",
       "      <td>-0.065875</td>\n",
       "      <td>0.033340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.011020</td>\n",
       "      <td>0.020083</td>\n",
       "      <td>-0.031212</td>\n",
       "      <td>-0.045765</td>\n",
       "      <td>0.037894</td>\n",
       "      <td>0.056620</td>\n",
       "      <td>-0.102423</td>\n",
       "      <td>0.054841</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>0.063985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005082</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>-0.109055</td>\n",
       "      <td>-0.054092</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.029158</td>\n",
       "      <td>0.040586</td>\n",
       "      <td>0.075685</td>\n",
       "      <td>-0.023683</td>\n",
       "      <td>-0.019473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.008838</td>\n",
       "      <td>0.035906</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>-0.052783</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>-0.013006</td>\n",
       "      <td>-0.002920</td>\n",
       "      <td>-0.073956</td>\n",
       "      <td>-0.029146</td>\n",
       "      <td>-0.005832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>-0.010715</td>\n",
       "      <td>0.046827</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.034628</td>\n",
       "      <td>0.031907</td>\n",
       "      <td>0.018596</td>\n",
       "      <td>0.082424</td>\n",
       "      <td>0.028690</td>\n",
       "      <td>0.058835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.014542</td>\n",
       "      <td>0.017227</td>\n",
       "      <td>0.038784</td>\n",
       "      <td>-0.062371</td>\n",
       "      <td>-0.013043</td>\n",
       "      <td>-0.042375</td>\n",
       "      <td>-0.028800</td>\n",
       "      <td>-0.039321</td>\n",
       "      <td>0.041385</td>\n",
       "      <td>0.072565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062471</td>\n",
       "      <td>-0.027543</td>\n",
       "      <td>-0.060659</td>\n",
       "      <td>-0.005309</td>\n",
       "      <td>-0.004941</td>\n",
       "      <td>0.025241</td>\n",
       "      <td>0.013002</td>\n",
       "      <td>0.172077</td>\n",
       "      <td>0.022104</td>\n",
       "      <td>0.007977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.092805</td>\n",
       "      <td>0.034149</td>\n",
       "      <td>-0.026214</td>\n",
       "      <td>-0.013556</td>\n",
       "      <td>0.013479</td>\n",
       "      <td>-0.045437</td>\n",
       "      <td>-0.042710</td>\n",
       "      <td>0.041257</td>\n",
       "      <td>0.099358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051143</td>\n",
       "      <td>0.030840</td>\n",
       "      <td>-0.024884</td>\n",
       "      <td>-0.134965</td>\n",
       "      <td>0.073629</td>\n",
       "      <td>0.020884</td>\n",
       "      <td>0.041751</td>\n",
       "      <td>0.065306</td>\n",
       "      <td>-0.014077</td>\n",
       "      <td>-0.012693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.004415</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>-0.020043</td>\n",
       "      <td>-0.027644</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>-0.053404</td>\n",
       "      <td>-0.090004</td>\n",
       "      <td>-0.071659</td>\n",
       "      <td>-0.007938</td>\n",
       "      <td>0.058854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020400</td>\n",
       "      <td>0.049585</td>\n",
       "      <td>-0.114788</td>\n",
       "      <td>-0.078019</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>-0.024812</td>\n",
       "      <td>0.118637</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>-0.016594</td>\n",
       "      <td>0.035050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.013948</td>\n",
       "      <td>0.037819</td>\n",
       "      <td>-0.042591</td>\n",
       "      <td>-0.042842</td>\n",
       "      <td>0.010634</td>\n",
       "      <td>-0.002923</td>\n",
       "      <td>-0.075844</td>\n",
       "      <td>-0.079600</td>\n",
       "      <td>0.049886</td>\n",
       "      <td>0.090189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043097</td>\n",
       "      <td>0.072517</td>\n",
       "      <td>-0.083576</td>\n",
       "      <td>-0.066676</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>-0.008819</td>\n",
       "      <td>0.117125</td>\n",
       "      <td>0.029278</td>\n",
       "      <td>-0.015145</td>\n",
       "      <td>0.059436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.001501</td>\n",
       "      <td>0.093722</td>\n",
       "      <td>0.028355</td>\n",
       "      <td>-0.025666</td>\n",
       "      <td>-0.010901</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>-0.040041</td>\n",
       "      <td>-0.038283</td>\n",
       "      <td>0.042444</td>\n",
       "      <td>0.084631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041236</td>\n",
       "      <td>0.035856</td>\n",
       "      <td>-0.024924</td>\n",
       "      <td>-0.149241</td>\n",
       "      <td>0.070737</td>\n",
       "      <td>0.030996</td>\n",
       "      <td>0.032543</td>\n",
       "      <td>0.054970</td>\n",
       "      <td>-0.017927</td>\n",
       "      <td>-0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>-0.045177</td>\n",
       "      <td>-0.046507</td>\n",
       "      <td>0.038470</td>\n",
       "      <td>-0.032353</td>\n",
       "      <td>-0.105851</td>\n",
       "      <td>-0.098844</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>0.088401</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061733</td>\n",
       "      <td>0.084054</td>\n",
       "      <td>-0.107516</td>\n",
       "      <td>-0.083581</td>\n",
       "      <td>-0.014805</td>\n",
       "      <td>-0.014066</td>\n",
       "      <td>0.088589</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.029425</td>\n",
       "      <td>0.035628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.024182</td>\n",
       "      <td>0.136141</td>\n",
       "      <td>0.108505</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>-0.057733</td>\n",
       "      <td>-0.093313</td>\n",
       "      <td>-0.087843</td>\n",
       "      <td>-0.090459</td>\n",
       "      <td>0.114988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176429</td>\n",
       "      <td>-0.027739</td>\n",
       "      <td>-0.088896</td>\n",
       "      <td>0.056054</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>0.092140</td>\n",
       "      <td>-0.037494</td>\n",
       "      <td>0.034797</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.036251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.006486</td>\n",
       "      <td>0.143426</td>\n",
       "      <td>0.106270</td>\n",
       "      <td>0.097436</td>\n",
       "      <td>0.025834</td>\n",
       "      <td>-0.061947</td>\n",
       "      <td>-0.110239</td>\n",
       "      <td>-0.101622</td>\n",
       "      <td>-0.075534</td>\n",
       "      <td>0.117639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178446</td>\n",
       "      <td>-0.021988</td>\n",
       "      <td>-0.073933</td>\n",
       "      <td>0.027435</td>\n",
       "      <td>-0.001602</td>\n",
       "      <td>0.078246</td>\n",
       "      <td>-0.042828</td>\n",
       "      <td>0.021507</td>\n",
       "      <td>-0.007158</td>\n",
       "      <td>0.048972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45 rows  64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.045718  0.029550 -0.006603 -0.030292  0.037942 -0.016469 -0.094294   \n",
       "1   0.014879  0.053706 -0.026616 -0.055694  0.026509 -0.097890 -0.020897   \n",
       "2  -0.025563  0.094409 -0.040374 -0.070944  0.156529 -0.005459 -0.025024   \n",
       "3   0.034758  0.041230  0.053005 -0.012524 -0.050618  0.050894 -0.061397   \n",
       "4  -0.050177  0.039690 -0.013134 -0.057276  0.044675  0.002194  0.001921   \n",
       "5  -0.014579  0.068516 -0.006934 -0.046155  0.016000  0.005347 -0.097081   \n",
       "6  -0.003845  0.025578 -0.016001 -0.068146 -0.084224 -0.011092 -0.076685   \n",
       "7   0.001945  0.137261  0.076068  0.071644  0.054881 -0.108232 -0.139761   \n",
       "8   0.025607  0.021977 -0.025969 -0.026830  0.027689  0.028476 -0.121105   \n",
       "9   0.031743  0.113015  0.034682 -0.006114 -0.006546 -0.061236 -0.013636   \n",
       "10  0.006413  0.073400  0.009594 -0.035093  0.000758  0.032547 -0.045356   \n",
       "11  0.008868  0.076600  0.006743 -0.053068 -0.006125  0.018379 -0.046418   \n",
       "12  0.046638  0.084531  0.082975 -0.036053 -0.003599  0.031197 -0.078514   \n",
       "13  0.016510  0.042524 -0.018867 -0.077157 -0.050874  0.050737 -0.015112   \n",
       "14 -0.019388  0.029920 -0.008551 -0.065558  0.058580  0.006604 -0.003221   \n",
       "15  0.012471  0.048493  0.006817 -0.049377  0.056934  0.036149 -0.097038   \n",
       "16  0.015493  0.119825  0.012335  0.094573 -0.006872 -0.052345  0.036623   \n",
       "17  0.002284  0.054157  0.008091 -0.010715  0.015597 -0.019786 -0.066090   \n",
       "18  0.033059  0.043817 -0.002383 -0.035188  0.023646 -0.009360 -0.000830   \n",
       "19  0.011671  0.085089  0.023694 -0.032689  0.004649  0.021086 -0.048543   \n",
       "20  0.016503  0.021980 -0.047566 -0.010999  0.046883 -0.020190 -0.088583   \n",
       "21  0.025232  0.076471  0.036902 -0.036584 -0.016119  0.022545 -0.045926   \n",
       "22 -0.014369  0.019009 -0.034077 -0.004060  0.018347 -0.006948 -0.075494   \n",
       "23  0.031779  0.120885 -0.003923  0.062244  0.017966 -0.019144  0.025218   \n",
       "24  0.009189  0.012822 -0.016392 -0.031908  0.026000 -0.027613 -0.080755   \n",
       "25  0.022119  0.090834  0.046463  0.047062  0.014813 -0.061685 -0.001193   \n",
       "26  0.015711  0.032453 -0.022631 -0.042749  0.036292 -0.029347 -0.093948   \n",
       "27  0.028160  0.076047  0.070391  0.012603 -0.015330 -0.012267 -0.057451   \n",
       "28  0.031323  0.082330  0.067633 -0.026719  0.024059 -0.021315 -0.114488   \n",
       "29  0.014051  0.081975  0.038148 -0.054412 -0.000611  0.027921 -0.041973   \n",
       "30 -0.007677  0.031448 -0.026275 -0.042163  0.036247  0.056189 -0.099280   \n",
       "31 -0.008793  0.035975 -0.047498 -0.052630  0.060049  0.049904 -0.100061   \n",
       "32  0.010835  0.013261 -0.054100 -0.033012  0.050905 -0.060793 -0.114428   \n",
       "33 -0.004711  0.037684 -0.028149 -0.042811  0.046165  0.054393 -0.088368   \n",
       "34  0.025028  0.023958 -0.001213 -0.057603 -0.073663  0.033400 -0.040789   \n",
       "35 -0.011020  0.020083 -0.031212 -0.045765  0.037894  0.056620 -0.102423   \n",
       "36 -0.008838  0.035906  0.000617 -0.052783  0.048780 -0.013006 -0.002920   \n",
       "37  0.014542  0.017227  0.038784 -0.062371 -0.013043 -0.042375 -0.028800   \n",
       "38  0.001225  0.092805  0.034149 -0.026214 -0.013556  0.013479 -0.045437   \n",
       "39 -0.004415  0.017101 -0.020043 -0.027644  0.000786 -0.053404 -0.090004   \n",
       "40  0.013948  0.037819 -0.042591 -0.042842  0.010634 -0.002923 -0.075844   \n",
       "41 -0.001501  0.093722  0.028355 -0.025666 -0.010901  0.009500 -0.040041   \n",
       "42  0.004113  0.018295 -0.045177 -0.046507  0.038470 -0.032353 -0.105851   \n",
       "43  0.024182  0.136141  0.108505  0.069285  0.028128 -0.057733 -0.093313   \n",
       "44 -0.006486  0.143426  0.106270  0.097436  0.025834 -0.061947 -0.110239   \n",
       "\n",
       "          7         8         9   ...        54        55        56        57  \\\n",
       "0  -0.019970 -0.014836  0.082431  ... -0.044541  0.055484 -0.101424 -0.070186   \n",
       "1  -0.097928 -0.014248  0.010718  ... -0.011992 -0.055746  0.078403  0.005336   \n",
       "2  -0.080697 -0.032454  0.163034  ... -0.018262 -0.037139  0.011970 -0.074624   \n",
       "3  -0.112498  0.039355  0.024527  ... -0.139965  0.122681 -0.043349 -0.016505   \n",
       "4  -0.077664 -0.065639 -0.031200  ... -0.000984 -0.005697  0.053840  0.021765   \n",
       "5  -0.084453  0.020215  0.074538  ... -0.046301  0.034606 -0.050701 -0.110988   \n",
       "6  -0.051530 -0.051489  0.038842  ... -0.026712 -0.009303  0.015449 -0.022771   \n",
       "7  -0.130954 -0.088365  0.100763  ... -0.214328 -0.034124 -0.086951 -0.035603   \n",
       "8  -0.104698  0.039678  0.127245  ... -0.100903  0.085193 -0.091519 -0.071606   \n",
       "9  -0.120102 -0.050542  0.134738  ... -0.140696  0.096582 -0.068511 -0.057512   \n",
       "10 -0.030846  0.019439  0.096794  ... -0.035799  0.063068 -0.029667 -0.100024   \n",
       "11 -0.018548  0.019612  0.071290  ... -0.033081  0.062438 -0.016117 -0.102073   \n",
       "12 -0.021192  0.052206  0.010567  ... -0.009988  0.030690 -0.044073 -0.085046   \n",
       "13 -0.024029 -0.042159  0.020356  ... -0.001702 -0.014505  0.006843 -0.034258   \n",
       "14 -0.070910 -0.041263 -0.026573  ...  0.041038  0.005778  0.049116  0.002152   \n",
       "15  0.015217 -0.034286  0.047402  ... -0.004971  0.076468 -0.096170 -0.012768   \n",
       "16 -0.082182 -0.006148  0.100742  ... -0.059317 -0.099608  0.027492 -0.099546   \n",
       "17 -0.101331  0.051375  0.088146  ... -0.100255  0.045570 -0.006339 -0.099822   \n",
       "18 -0.057167 -0.057007  0.029630  ... -0.007441 -0.005505  0.039446  0.029894   \n",
       "19 -0.016978  0.043538  0.113206  ... -0.033911  0.037789 -0.041902 -0.152079   \n",
       "20 -0.108168  0.036541  0.079289  ... -0.068870  0.068981 -0.088746 -0.072308   \n",
       "21  0.008312  0.003144  0.096071  ... -0.030195  0.032805 -0.033361 -0.145777   \n",
       "22 -0.071101  0.001313  0.079337  ... -0.027003  0.057400 -0.100435 -0.103675   \n",
       "23 -0.099728  0.018702  0.172826  ... -0.044301 -0.065676  0.022779 -0.113362   \n",
       "24 -0.123708 -0.000170  0.054489  ... -0.092378  0.027401 -0.077702 -0.088449   \n",
       "25 -0.141387 -0.021373  0.126997  ... -0.023251 -0.048002 -0.019405 -0.080486   \n",
       "26 -0.103322  0.005375  0.073889  ... -0.078985  0.045724 -0.081404 -0.079405   \n",
       "27 -0.121926  0.064830  0.040397  ... -0.095598  0.071496 -0.043650 -0.002025   \n",
       "28 -0.051262  0.054604  0.044275  ... -0.085564  0.028727 -0.090319 -0.092322   \n",
       "29  0.002536 -0.012894  0.108911  ... -0.042799  0.045160 -0.031504 -0.162719   \n",
       "30  0.032602 -0.042544  0.053963  ...  0.001731  0.100519 -0.091380 -0.021080   \n",
       "31  0.027434 -0.005198  0.060145  ... -0.023003  0.066782 -0.107320 -0.062841   \n",
       "32 -0.142502 -0.007025  0.055599  ... -0.077932  0.049478 -0.107377 -0.069877   \n",
       "33  0.031845 -0.043457  0.063833  ...  0.001374  0.080604 -0.088755 -0.039875   \n",
       "34 -0.035487 -0.040247  0.020686  ... -0.019669 -0.019787  0.024693 -0.043907   \n",
       "35  0.054841 -0.016570  0.063985  ... -0.005082  0.089552 -0.109055 -0.054092   \n",
       "36 -0.073956 -0.029146 -0.005832  ...  0.016949 -0.010715  0.046827  0.008312   \n",
       "37 -0.039321  0.041385  0.072565  ... -0.062471 -0.027543 -0.060659 -0.005309   \n",
       "38 -0.042710  0.041257  0.099358  ... -0.051143  0.030840 -0.024884 -0.134965   \n",
       "39 -0.071659 -0.007938  0.058854  ... -0.020400  0.049585 -0.114788 -0.078019   \n",
       "40 -0.079600  0.049886  0.090189  ... -0.043097  0.072517 -0.083576 -0.066676   \n",
       "41 -0.038283  0.042444  0.084631  ... -0.041236  0.035856 -0.024924 -0.149241   \n",
       "42 -0.098844 -0.000602  0.088401  ... -0.061733  0.084054 -0.107516 -0.083581   \n",
       "43 -0.087843 -0.090459  0.114988  ... -0.176429 -0.027739 -0.088896  0.056054   \n",
       "44 -0.101622 -0.075534  0.117639  ... -0.178446 -0.021988 -0.073933  0.027435   \n",
       "\n",
       "          58        59        60        61        62        63  \n",
       "0   0.006019  0.029890  0.090776  0.048945  0.032682  0.025100  \n",
       "1  -0.027869 -0.003987  0.028131  0.107723  0.034473  0.030731  \n",
       "2   0.048606  0.013519  0.093437  0.066523 -0.047791 -0.023772  \n",
       "3   0.013531  0.004904  0.054962  0.005899  0.011502  0.007898  \n",
       "4   0.003299  0.047243  0.057308  0.103604 -0.004837  0.013525  \n",
       "5   0.076473  0.027367  0.031817  0.073614  0.004667 -0.048693  \n",
       "6   0.096020  0.043913  0.032230  0.028959 -0.101444  0.006620  \n",
       "7  -0.018621  0.015729 -0.053997  0.040064 -0.000530  0.042536  \n",
       "8   0.011091 -0.020740  0.127078  0.006519  0.021186  0.070626  \n",
       "9   0.016246 -0.024609  0.093552  0.073588  0.147881 -0.008034  \n",
       "10  0.028501  0.030769  0.055624  0.065867 -0.032114 -0.054099  \n",
       "11  0.069959  0.044119  0.052977  0.064947 -0.030324 -0.036588  \n",
       "12  0.106871 -0.035433  0.060999  0.027977  0.062490 -0.033624  \n",
       "13  0.044570  0.023196  0.056535 -0.006508 -0.065058  0.010104  \n",
       "14  0.021475  0.036974  0.010041  0.082808  0.014177  0.013240  \n",
       "15  0.007764 -0.002510  0.078921  0.041989  0.011758 -0.039439  \n",
       "16 -0.006016 -0.100893  0.014221  0.011576  0.080198 -0.050756  \n",
       "17  0.058728  0.027287  0.053411  0.059347 -0.018454  0.008276  \n",
       "18 -0.003873  0.033013  0.019739  0.114780  0.070594  0.058180  \n",
       "19  0.064484  0.004390  0.034925  0.067526  0.006412 -0.056446  \n",
       "20  0.000139 -0.009332  0.113710  0.034265  0.016250  0.044791  \n",
       "21  0.094102  0.010926  0.028587  0.084461 -0.006333 -0.068345  \n",
       "22  0.004587  0.014840  0.088782  0.012776  0.032527  0.010783  \n",
       "23  0.010419 -0.049550  0.008982  0.018996  0.047716  0.043224  \n",
       "24  0.003402 -0.003518  0.073781  0.033179  0.053518  0.011284  \n",
       "25 -0.006526 -0.043165 -0.007972  0.030078  0.064146 -0.027547  \n",
       "26 -0.019545  0.005836  0.097253  0.031109  0.037987  0.029841  \n",
       "27  0.059618  0.051520  0.037757  0.027529 -0.037450  0.041332  \n",
       "28  0.037236 -0.036258  0.070299  0.025292  0.071249 -0.021214  \n",
       "29  0.081387  0.022862  0.033945  0.048436 -0.000999 -0.061317  \n",
       "30  0.012255  0.055066  0.029710  0.055870 -0.022828 -0.055748  \n",
       "31 -0.020343  0.031354  0.075387  0.066222 -0.025534 -0.024558  \n",
       "32 -0.022323 -0.023003  0.103833  0.040407  0.033367  0.039933  \n",
       "33  0.003098  0.052876  0.029805  0.068806 -0.020217 -0.053999  \n",
       "34  0.036896  0.034142  0.049083  0.015043 -0.065875  0.033340  \n",
       "35 -0.000385  0.029158  0.040586  0.075685 -0.023683 -0.019473  \n",
       "36  0.034628  0.031907  0.018596  0.082424  0.028690  0.058835  \n",
       "37 -0.004941  0.025241  0.013002  0.172077  0.022104  0.007977  \n",
       "38  0.073629  0.020884  0.041751  0.065306 -0.014077 -0.012693  \n",
       "39  0.010994 -0.024812  0.118637  0.011356 -0.016594  0.035050  \n",
       "40  0.016868 -0.008819  0.117125  0.029278 -0.015145  0.059436  \n",
       "41  0.070737  0.030996  0.032543  0.054970 -0.017927 -0.032258  \n",
       "42 -0.014805 -0.014066  0.088589  0.003711  0.029425  0.035628  \n",
       "43 -0.000097  0.092140 -0.037494  0.034797  0.000834  0.036251  \n",
       "44 -0.001602  0.078246 -0.042828  0.021507 -0.007158  0.048972  \n",
       "\n",
       "[45 rows x 64 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_embseq.emb_seq.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_exploded = explode_train_target(train_target)\n",
    "train_embs_df = pd.DataFrame(train_embs.tolist())\n",
    "train_embs_df = pd.concat([train_target_exploded, train_embs_df], axis=1)\n",
    "train_embseq = merge_embs_to_seq(train_target, train_embs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embs_df['NOTE_ID'] = train_target_exploded['NOTE_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embseq.emb_seq.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_exploded = explode_train_target(train_target)\n",
    "train_target_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_exploded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clinical1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
